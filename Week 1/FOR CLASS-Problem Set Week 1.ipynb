{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Problem Set: Potential Outcomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "In this problem set, we seek to build an understanding of the Potential Outcomes framework for understanding the value of experiments. I provide a stylized example of sales of Chipotle on the DoorDash App. The data set is from an \"omniscient observer\", where we can see the outcome for each individual when treated or not. Of course, such a dataset could never actually exist in real-life. Through the course of this problem set, we will ask you to simulate analysis based on subsets of the data that could actually be observed.\n",
    "\n",
    "In this example we look at 40 DoorDash users, and track the amount of Chipotle they purchase of the course of 6 months. Some users receive the banner promotion and some do not.  \n",
    "- 'Y1' represents total  chipotle sales for a user, had they been shown a  banner promotion\n",
    "- 'Y0' represents total  chipotle sales for a user, had they *not* been shown a banner\n",
    "\n",
    "However, in DoorDash's app, we  assume they created a production experience where they showed the banner to users within 3 miles of a Chipotle and did not show it to users further away.  \n",
    "- 'near_chipotle' is a binary flag for whether a user's home address was within 3 miles of a Chipotle\n",
    "- 'production_treatment' is a binary flag for whether the user is shown a banner promotion in DoorDash's production (or primary) app. \n",
    "- you should notice, these are identical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Simple Difference in Outcomes\n",
    "- A Read in the dataset\n",
    "- B: Recreate what the dataset would look like when run in production. Create a variable *production_Y*, which is the observed outcome for each user. You should be able to do this with the switching equation\n",
    "- C: Calculate the *Simple Difference In Outcomes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (continued)\n",
    "- D: Calculate the Selection Bias\n",
    "- E: Calculate the Heterogeneous Treatment Effect Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (continued)\n",
    "- F: Combine (C,D,E) to calculate the Average Treatment Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Simulate an Experiment\n",
    "If DoorDash ran a randomized experiment, they would have a different data set to observe. Now create what a dataset would look like had the experiment been run\n",
    "- A: Create a new variable *experiment_treatment*, where a random 50% percent of users are treated with the Banner Promotion, and the other 50% are not\n",
    "- B: Create a new variable *experiment_y* which is the observed outcome for each user from this hypothetical experiment. \n",
    "- C: Calculate the average treatment effect from this experiment\n",
    "- D: Repeat this calculation 1000 times. Plot a histogram of the estimated average treatment effects. What is the mean and variance of the average treatment effect? (You will be asked to used the reuse the analysis you did in 2B and 2C in problem 3. You may want to make a copy of this dataframe or create a new variable to handle your simulations). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Permutation Testing\n",
    "\n",
    "Go back to a dataset like the one you created in 2a and 2b, with one experimental treatment and one experimental outcome. We now want to introduce a new concept called randomization based inference. In this, we compare the outcomes of an experiment against a null hypotheses (called the sharp null) that there is no treatment effect for any individual. \n",
    "\n",
    "Under this null hypothesis, we would have expected to see the observed results (*experiment_y*) no matter how treatment was assigned. So we can simulate other, hypothetical experiments,  without changing the outcomes to  calculate average treatment effects. You can read about this approach in *Causal Inference: The Mixtape\" (pages 148-163)\n",
    "\n",
    "- A: Create a new variable *permuted_treatement* with a 50% of being treated and a 50% chance of not being treated\n",
    "- B: Calculate the average treatment effect under the sharp null hypothesis, using experiment_y and permuted_treatement\n",
    "- C: Repeat this 1000 times. What is the average of the simulated average treatment effect under the null hypothesis. Plot a histogram of the outcomes\n",
    "- D: What was the probability of seeing a treatment effect as large the treatment effect calculated in 2C. \n",
    "- E: In your words, explain what the probability calculated in 3D means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
